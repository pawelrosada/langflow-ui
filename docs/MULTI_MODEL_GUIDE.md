# Multi-Model LangFlow Pipeline Enhancement Documentation

This document provides comprehensive guidance on the new multi-model capabilities added to enhance Copilot's ability to generate universal LangFlow pipelines.

## 🚀 Overview

The enhancement adds powerful multi-model support to the LangFlow-OpenWebUI integration, enabling:

- **Dynamic model selection** via user input directives
- **Agentic routing** that automatically selects the best model based on query content
- **Universal API templates** for handling multiple models in single or multi-script architectures
- **LangFlow workflow templates** that support multiple AI models in visual workflows
- **Backward compatibility** with existing single-model setups

## 🏗 Architecture

### Enhanced Pipeline Architecture

```
┌─────────────────────────────────────────────────────────┐
│                 Enhanced Pipeline                        │
│  ┌─────────────────────────────────────────────────────┐ │
│  │            User Input Processing                    │ │
│  │  @model:gemini | @model:gpt | @model:claude | @agent│ │
│  └─────────────────────────────────────────────────────┘ │
│                           │                             │
│                           ▼                             │
│  ┌─────────────────────────────────────────────────────┐ │
│  │              Model Selection Logic                  │ │
│  │   • Directive parsing                              │ │
│  │   • Content analysis                               │ │
│  │   • Intelligent routing                            │ │
│  └─────────────────────────────────────────────────────┘ │
│                           │                             │
│                           ▼                             │
│  ┌─────────────────────────────────────────────────────┐ │
│  │             LangFlow API Integration                │ │
│  │  • Model-specific tweaks                           │ │
│  │  • Workflow ID routing                             │ │
│  │  • Universal workflow support                      │ │
│  └─────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

### API Template Options

#### Option 1: Single-Script Multi-Model API
- **File**: `templates/multi_model_api_single.py`
- **Port**: 8000 (configurable)
- **Use case**: Simple deployments, development, testing

#### Option 2: Multi-Script Scalable Architecture
- **Files**: Generated by `templates/generate_multi_scripts.py`
- **Ports**: Gemini (8001), GPT (8002), Claude (8003)
- **Use case**: Production deployments, high availability, isolation

## 📋 Components

### 1. Enhanced Pipeline (`pipelines/enhanced_langflow_pipeline.py`)

**New Features:**
- Multi-model support with backward compatibility
- User directive parsing (`@model:modelname`, `@agent`)
- Intelligent content-based routing
- Model-specific workflow ID support
- Universal workflow integration

**Configuration Valves:**
```python
ENABLE_MULTI_MODEL: bool = True          # Enable multi-model features
DEFAULT_MODEL: str = "gpt"               # Default model selection
ENABLE_AGENTIC_ROUTING: bool = True      # Smart routing
UNIVERSAL_WORKFLOW_ID: str = ""          # Universal workflow support
GEMINI_WORKFLOW_ID: str = ""             # Model-specific workflows
GPT_WORKFLOW_ID: str = ""
CLAUDE_WORKFLOW_ID: str = ""
```

### 2. API Templates (`templates/`)

#### Single-Script API (`multi_model_api_single.py`)
- FastAPI application with multiple model endpoints
- Dynamic routing: `/invoke/{flow_id}/{model_name}`
- Agentic endpoint: `/invoke/agent/{flow_id}` 
- Health checking and model status

#### Multi-Script Generator (`generate_multi_scripts.py`)
- Generates individual API scripts per model
- Creates orchestrator for managing multiple services
- Provides isolation and scalability

#### Universal Workflow Generator (`generate_universal_workflows.py`)
- Creates LangFlow JSON workflows for multi-model scenarios
- Supports manual model selection and automatic routing
- UI-friendly for visual editing in LangFlow

### 3. Workflow Templates (`templates/examples/langflow-workflows/`)

#### Universal Multi-Model Chat (`universal-multi-model-chat.json`)
- Manual model selection via dropdown
- Single workflow handling all models
- Perfect for testing different models with same input

#### Agentic Multi-Model Router (`agentic-multi-model-router.json`)
- Automatic model selection based on content analysis
- Smart routing logic embedded in workflow
- Transparent model switching

## 🔧 Usage Guide

### Basic Multi-Model Usage in OpenWebUI

Once the enhanced pipeline is configured, users can:

```
# Explicit model selection
@model:gemini What's the latest in AI research?
@model:gpt Write a creative short story about robots
@model:claude Help me debug this Python function

# Automatic intelligent routing
@agent How do I implement a binary search tree?  # → Routes to Claude
@agent What's happening in tech news today?      # → Routes to Gemini
@agent Write a poem about the ocean             # → Routes to GPT
```

### API Template Usage

#### Using Single-Script API:
```bash
# Setup
export GEMINI_API_KEY="your-key"
export OPENAI_API_KEY="your-key"
export ANTHROPIC_API_KEY="your-key"

# Run
python templates/multi_model_api_single.py

# Test
curl -X POST "http://localhost:8000/invoke/my-flow-id/gemini" \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello world", "temperature": 0.7}'
```

#### Using Multi-Script Architecture:
```bash
# Generate scripts
cd templates
python generate_multi_scripts.py

# Run all services
python orchestrator.py start

# Individual service testing
curl -X POST "http://localhost:8001/invoke/my-flow-id" \
  -d '{"message": "Hello Gemini"}'
```

### Workflow Template Usage

#### Import into LangFlow:
1. Open LangFlow at http://localhost:7860
2. Click "Import" and select workflow JSON
3. Configure API keys in model components
4. Test the multi-model workflow

#### Generated Workflows Support:
- **Dynamic model switching** without rebuilding workflows
- **Visual editing** of routing logic
- **Easy export/import** for version control

## ⚙️ Configuration Options

### Enhanced Pipeline Configuration

Set environment variables or configure in OpenWebUI:

```bash
# Multi-model settings
ENABLE_MULTI_MODEL=true
DEFAULT_MODEL=gpt
ENABLE_AGENTIC_ROUTING=true

# Workflow routing
UNIVERSAL_WORKFLOW_ID=your-universal-flow-id
GEMINI_WORKFLOW_ID=your-gemini-specific-flow
GPT_WORKFLOW_ID=your-gpt-specific-flow
CLAUDE_WORKFLOW_ID=your-claude-specific-flow

# API keys for tweaks
GEMINI_API_KEY=your-gemini-key
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
```

### Model Routing Logic

The intelligent routing analyzes input for keywords:

```python
# Content-based routing examples
"python code" → Claude (technical/coding)
"creative story" → GPT (creative writing)
"latest news" → Gemini (search/current info)
```

Custom routing logic can be modified in `select_model_by_content()` method.

## 🚀 Deployment Scenarios

### Development/Testing
- Use single-script API with enhanced pipeline
- Import universal workflow templates
- Test different models interactively

### Production
- Use multi-script architecture for scalability
- Deploy with Docker containers
- Use load balancing for high availability
- Monitor individual model performance

### Integration with Existing Setups
- Enhanced pipeline maintains backward compatibility
- Original workflows continue to work
- Gradual migration to multi-model capabilities

## 🔍 Troubleshooting

### Common Issues

**Pipeline Not Loading:**
```bash
# Check Python path and imports
cd pipelines
python -c "from enhanced_langflow_pipeline import Pipeline; print('OK')"
```

**Model Selection Not Working:**
- Verify `ENABLE_MULTI_MODEL=true`
- Check directive syntax: `@model:gemini` (not `@model gemini`)
- Ensure model name is valid: gemini, gpt, claude

**API Templates Not Starting:**
```bash
# Check dependencies
pip install fastapi uvicorn httpx pydantic

# Verify syntax
python -m py_compile templates/multi_model_api_single.py
```

**Workflow Templates Not Loading:**
- Verify JSON syntax with `python -m json.tool workflow.json`
- Check LangFlow version compatibility
- Ensure all required nodes are available

### Debug Mode

Enable enhanced logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Testing

Run comprehensive test suite:
```bash
python tests/test_multi_model_enhancements.py
```

## 📚 Advanced Topics

### Custom Model Integration

Add new models by extending the `models` dictionary:

```python
models = {
    # ... existing models ...
    "custom_model": {
        "model": "custom-model-version",
        "display_name": "Custom Model",
        "keywords": ["custom", "specific", "keywords"]
    }
}
```

### Workflow Customization

Modify workflow generators to create custom node types:
- Add new model components
- Implement custom routing logic  
- Create specialized workflow patterns

### API Extension

Extend API templates with:
- Additional model providers
- Custom routing algorithms
- Advanced monitoring and metrics
- Authentication and rate limiting

## 🤝 Contributing

When enhancing these templates for Copilot:

1. **Maintain Simplicity** - Keep code readable for AI understanding
2. **Use Clear Comments** - Brief English explanations
3. **Follow Patterns** - Consistent structure across components
4. **Test Integration** - Ensure OpenWebUI compatibility
5. **Document Changes** - Update relevant documentation

## 📖 Related Resources

- [LangFlow Documentation](https://docs.langflow.org/)
- [OpenWebUI Pipelines](https://docs.openwebui.com/pipelines/)  
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Pydantic Models](https://docs.pydantic.dev/)

---

**This enhancement enables Copilot to generate sophisticated multi-model LangFlow pipelines with minimal configuration and maximum flexibility!**